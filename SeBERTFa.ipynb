{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d9936a-35c0-4b57-a27c-68b5d31e1b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:19:48.931487Z",
     "iopub.status.busy": "2022-01-28T07:19:48.931270Z",
     "iopub.status.idle": "2022-01-28T07:20:04.670472Z",
     "shell.execute_reply": "2022-01-28T07:20:04.669798Z",
     "shell.execute_reply.started": "2022-01-28T07:19:48.931462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2936a84b-fedb-4e9c-a1dc-17b351597ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:20:04.671902Z",
     "iopub.status.busy": "2022-01-28T07:20:04.671723Z",
     "iopub.status.idle": "2022-01-28T07:20:06.639035Z",
     "shell.execute_reply": "2022-01-28T07:20:06.638683Z",
     "shell.execute_reply.started": "2022-01-28T07:20:04.671879Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 07:20:05.596964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# import all it's needed\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from datasets import load_dataset, load_from_disk, load_metric\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from hazm import *\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8847787-678d-44e7-b2c5-5ea73993c62a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:20:06.639604Z",
     "iopub.status.busy": "2022-01-28T07:20:06.639518Z",
     "iopub.status.idle": "2022-01-28T07:21:19.220158Z",
     "shell.execute_reply": "2022-01-28T07:21:19.219713Z",
     "shell.execute_reply.started": "2022-01-28T07:20:06.639592Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.56k/1.56k [00:00<00:00, 1.26MB/s]\n",
      "Downloading: 100%|██████████| 621M/621M [00:54<00:00, 12.0MB/s]  \n",
      "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased-clf-digimag were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 62.0/62.0 [00:00<00:00, 35.3kB/s]\n",
      "Downloading: 100%|██████████| 1.14M/1.14M [00:00<00:00, 2.83MB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 98.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "word_embedding_model = models.Transformer('HooshvareLab/bert-fa-base-uncased-clf-digimag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53e2535-9b40-46a1-bcf9-25db51197845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:21:19.220995Z",
     "iopub.status.busy": "2022-01-28T07:21:19.220905Z",
     "iopub.status.idle": "2022-01-28T07:21:19.317838Z",
     "shell.execute_reply": "2022-01-28T07:21:19.317415Z",
     "shell.execute_reply.started": "2022-01-28T07:21:19.220984Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "puncs = ['،', '.', ',', ':', ';', '\"']\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    doc = normalizer.normalize(doc) # Normalize document using Hazm Normalizer\n",
    "    tokenized = word_tokenize(doc)  # Tokenize text\n",
    "    tokens = []\n",
    "    for t in tokenized:\n",
    "      temp = t\n",
    "      for p in puncs:\n",
    "        temp = temp.replace(p, '')\n",
    "      tokens.append(temp)\n",
    "    # tokens = [w for w in tokens if not w in stop_set]    # Remove stop words\n",
    "    tokens = [w for w in tokens if not len(w) <= 1]\n",
    "    tokens = [w for w in tokens if not w.isdigit()]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens] # Lemmatize sentence words using Hazm Lemmatizer\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de2ac89-ce29-4160-bb2d-b7a3e133771a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:23:52.138547Z",
     "iopub.status.busy": "2022-01-28T07:23:52.138324Z",
     "iopub.status.idle": "2022-01-28T07:23:53.928023Z",
     "shell.execute_reply": "2022-01-28T07:23:53.927607Z",
     "shell.execute_reply.started": "2022-01-28T07:23:52.138521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare train data\n",
    "original = pd.read_csv('Dataset/original.csv',\n",
    "                       names=[\"text\", \"labels\"], index_col=None, header=None, encoding=\"utf-8\")\n",
    "balanced = pd.read_csv('Dataset/balanced.csv',\n",
    "                       names=[\"text\", \"labels\"], index_col=None, header=None, encoding=\"utf-8\")\n",
    "translation = pd.read_csv('Dataset/translation.csv',\n",
    "                          names=[\"text\", \"labels\"], index_col=None, header=None, encoding=\"utf-8\")\n",
    "# we just use of translation data so we can compare the result fairly to previous works.\n",
    "train = translation\n",
    "# cleaning text\n",
    "train['text'] = train.apply(lambda row:clean_doc(row.text), axis=1)\n",
    "# +2 make the label in range 0, 5 so it's now aceptable for rest of the process \n",
    "train['labels'] = train['labels'] + 2\n",
    "# save as parquet in storage so we can load it by transformes dataset\n",
    "train.to_parquet('Dataset/train.parquet', index=False)\n",
    "# prepare test data for reporting evaluation on it\n",
    "test = pd.read_csv('Dataset/test.csv',\n",
    "                   names=[\"text\", \"labels\"], index_col=None, header=None, encoding=\"utf-8\")\n",
    "# cleaning text\n",
    "test['text'] = test.apply(lambda row:clean_doc(row.text), axis=1)\n",
    "# +2 make the label in range 0, 5 so it's now aceptable for rest of the process \n",
    "test['labels'] = test['labels'] + 2\n",
    "# save as parquet in storage so we can load it by transformes dataset\n",
    "test.to_parquet('Dataset/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a940ef9-9bdf-466d-be2f-eee711ec1aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:25:43.908223Z",
     "iopub.status.busy": "2022-01-28T07:25:43.907999Z",
     "iopub.status.idle": "2022-01-28T07:25:48.936342Z",
     "shell.execute_reply": "2022-01-28T07:25:48.936041Z",
     "shell.execute_reply.started": "2022-01-28T07:25:43.908196Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2022-01-28 07:25:44,954.954 datasets.builder] Using custom data configuration default-d8be219597c4581e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /home/jovyan/.cache/huggingface/datasets/parquet/default-d8be219597c4581e/0.0.0/1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 4019.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1290.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/parquet/default-d8be219597c4581e/0.0.0/1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 933.31it/s]\n",
      "100%|██████████| 1756/1756 [00:02<00:00, 656.69ba/s]\n",
      "100%|██████████| 232/232 [00:00<00:00, 669.86ba/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"parquet\", data_files={'train': 'Dataset/train.parquet',\n",
    "                                              'test': 'Dataset/test.parquet'})\n",
    "\n",
    "# tokenize and padding\n",
    "def tokenize_function(data_point):\n",
    "    return word_embedding_model.tokenizer(data_point[\"text\"], padding='max_length', truncation=True, max_length=64)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, \n",
    "                                 remove_columns=[\"text\"],\n",
    "                                 batched=True,\n",
    "                                 batch_size=8)\n",
    "# split into train and test and shuffle so each batch is an unbiased sample of entire dataset\n",
    "full_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=43)\n",
    "full_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584e4b95-1e4e-42a8-b19c-70b7f3df7e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:27:16.367611Z",
     "iopub.status.busy": "2022-01-28T07:27:16.367210Z",
     "iopub.status.idle": "2022-01-28T07:27:16.420562Z",
     "shell.execute_reply": "2022-01-28T07:27:16.420185Z",
     "shell.execute_reply.started": "2022-01-28T07:27:16.367582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# avg pooling strategy for getting avg of each word embedding to obtain sentence embedding\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# add the layer above on top of the parsBERT model to get embedding of each sent in 768 dim.\n",
    "sent_bert_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49230e01-18f8-4c21-8678-3ad2aa9ca464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:28:20.367800Z",
     "iopub.status.busy": "2022-01-28T07:28:20.367525Z",
     "iopub.status.idle": "2022-01-28T07:28:20.372669Z",
     "shell.execute_reply": "2022-01-28T07:28:20.372157Z",
     "shell.execute_reply.started": "2022-01-28T07:28:20.367775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this class play a classifier role so we make it by sent_embedding(sent_bert_model)+dropout+linear\n",
    "class SentimentModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, sent_bert_model):\n",
    "        super(SentimentModel, self).__init__()\n",
    "\n",
    "        self.sent_bert_model = sent_bert_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(768, 5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_token):\n",
    "        output = self.sent_bert_model(input_token)\n",
    "        logits = self.classifier(output['sentence_embedding'])\n",
    "        return {'logits': logits} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a7e558-4b24-463e-960f-683a7105a169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:28:25.518717Z",
     "iopub.status.busy": "2022-01-28T07:28:25.518498Z",
     "iopub.status.idle": "2022-01-28T07:28:25.521871Z",
     "shell.execute_reply": "2022-01-28T07:28:25.521422Z",
     "shell.execute_reply.started": "2022-01-28T07:28:25.518693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_model = SentimentModel(sent_bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9633fd0-9472-4282-ac27-4d31f01d4583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:28:52.958999Z",
     "iopub.status.busy": "2022-01-28T07:28:52.958729Z",
     "iopub.status.idle": "2022-01-28T07:28:55.499445Z",
     "shell.execute_reply": "2022-01-28T07:28:55.499042Z",
     "shell.execute_reply.started": "2022-01-28T07:28:52.958974Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 5.29kB [00:00, 3.65MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "# metrics that use in this sentiment analysis research path\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    res_metric = metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return res_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ff0564-524f-4196-8544-0f7118eb90e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:30:02.114127Z",
     "iopub.status.busy": "2022-01-28T07:30:02.113912Z",
     "iopub.status.idle": "2022-01-28T07:30:02.122502Z",
     "shell.execute_reply": "2022-01-28T07:30:02.121874Z",
     "shell.execute_reply.started": "2022-01-28T07:30:02.114103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we implement cross entropy loss into comput_loss fn in transformer trainer in order to train our classification problem\n",
    "# we implement custom pytorch data loader as well\n",
    "class SentimentTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    def get_train_dataloader(self):\n",
    "        train_dataset = self.train_dataset\n",
    "        return torch.utils.data.DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=self.args.per_device_train_batch_size,\n",
    "                collate_fn=self.data_collator,\n",
    "                num_workers=self.args.dataloader_num_workers,\n",
    "                pin_memory=self.args.dataloader_pin_memory,\n",
    "            )\n",
    "    \n",
    "    def get_eval_dataloader(self, eval_dataset: Optional[torch.utils.data.Dataset] = None):\n",
    "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
    "        return torch.utils.data.DataLoader(\n",
    "                eval_dataset,\n",
    "                batch_size=self.args.eval_batch_size,\n",
    "                collate_fn=self.data_collator,\n",
    "                num_workers=self.args.dataloader_num_workers,\n",
    "                pin_memory=self.args.dataloader_pin_memory,\n",
    "            )\n",
    "    \n",
    "    def get_test_dataloader(self, test_dataset: torch.utils.data.Dataset):\n",
    "        return torch.utils.data.DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=self.args.eval_batch_size,\n",
    "                collate_fn=self.data_collator,\n",
    "                num_workers=self.args.dataloader_num_workers,\n",
    "                pin_memory=self.args.dataloader_pin_memory,\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a29a32b-f5a9-4fce-94e2-7ac6d041dd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:30:18.254902Z",
     "iopub.status.busy": "2022-01-28T07:30:18.254682Z",
     "iopub.status.idle": "2022-01-28T07:30:18.268191Z",
     "shell.execute_reply": "2022-01-28T07:30:18.267765Z",
     "shell.execute_reply.started": "2022-01-28T07:30:18.254878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer args\n",
    "training_args = TrainingArguments(\"transformers-sentiment\", \n",
    "                                  per_device_train_batch_size=2, \n",
    "                                  per_device_eval_batch_size=64,\n",
    "                                  num_train_epochs=3,\n",
    "                                  eval_accumulation_steps=1,\n",
    "                                  dataloader_num_workers=8,\n",
    "                                  gradient_accumulation_steps = 64,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0dbe85-d982-4862-8d9e-d8cd9bf8f989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:30:55.108700Z",
     "iopub.status.busy": "2022-01-28T07:30:55.108501Z",
     "iopub.status.idle": "2022-01-28T07:30:58.079460Z",
     "shell.execute_reply": "2022-01-28T07:30:58.079103Z",
     "shell.execute_reply.started": "2022-01-28T07:30:55.108684Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiate trainer with pre-defined model,datasets and metrics\n",
    "trainer = SentimentTrainer(\n",
    "    model=sent_model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_eval_dataset,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80fdf6d0-2011-4c64-8856-ec1c8acba8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T07:31:03.369368Z",
     "iopub.status.busy": "2022-01-28T07:31:03.369144Z",
     "iopub.status.idle": "2022-01-28T07:41:24.764751Z",
     "shell.execute_reply": "2022-01-28T07:41:24.764365Z",
     "shell.execute_reply.started": "2022-01-28T07:31:03.369341Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14046\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 64\n",
      "  Total optimization steps = 327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1854\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "{'eval_loss': 0.7324211001396179, 'eval_f1': 0.7166341420223062, 'eval_runtime': 2.843, 'eval_samples_per_second': 652.124, 'eval_steps_per_second': 10.2, 'epoch': 0.99}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1854\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "{'eval_loss': 0.7197931408882141, 'eval_f1': 0.7253228742594237, 'eval_runtime': 2.8207, 'eval_samples_per_second': 657.292, 'eval_steps_per_second': 10.281, 'epoch': 1.99}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1854\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7240970134735107, 'eval_f1': 0.7354990965370065, 'eval_runtime': 2.8263, 'eval_samples_per_second': 655.977, 'eval_steps_per_second': 10.261, 'epoch': 2.99}\n",
      "{'train_runtime': 621.3771, 'train_samples_per_second': 67.814, 'train_steps_per_second': 0.526, 'train_loss': 0.736384913826572, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=327, training_loss=0.736384913826572, metrics={'train_runtime': 621.3771, 'train_samples_per_second': 67.814, 'train_steps_per_second': 0.526, 'train_loss': 0.736384913826572, 'epoch': 2.99})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training phase\n",
    "trainer.train()\n",
    "# we can check the f1-score in printed logs below it was printed by the name \"eval_f1\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
